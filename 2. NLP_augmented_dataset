{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["wlMWRbonGiRG","cGpap45HGkit","muGSubw1G48V"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rxRVAQLfWgc6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","import sys\n","sys.path.append(\"/drive/MyDrive/CS7650_NLP_Project\")\n","path = \"./drive/MyDrive/CS7650_NLP_Project/\""]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"GADTImwpWg9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade pandas==1.4.4"],"metadata":{"id":"xvWn4RuuX_Se"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Import dataset"],"metadata":{"id":"wlMWRbonGiRG"}},{"cell_type":"code","source":["train = pd.read_pickle(path+\"dataset/train.pkl\")"],"metadata":{"id":"_hZXvy3kWhvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"t-_pcNUTdC5m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Get data with disability\n","- <= 2 (physical | il | pm | other)"],"metadata":{"id":"cGpap45HGkit"}},{"cell_type":"code","source":["train = train.sample(frac=1, random_state=42).reset_index()\n","train = train[train['disability_bin'] == 'Yes']\n","train = train[(train['physical_cat'] <= '2') | (train['il_cat'] <= '2') | (train['pm_cat'] <= '2') | (train['other_cat'] <= '2')]"],"metadata":{"id":"aztGM0VtWhyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.physical_cat.value_counts().sort_index()"],"metadata":{"id":"x45AbOBT_hh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.il_cat.value_counts().sort_index()"],"metadata":{"id":"B0AYZqTz_pDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.pm_cat.value_counts().sort_index()"],"metadata":{"id":"Htq8H-BV_r5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.other_cat.value_counts().sort_index()"],"metadata":{"id":"EgcphH3F_uqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.toxic_class.value_counts()"],"metadata":{"id":"raAFifVzBq09"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Manually adjust the subset of the datasets' ratio\n","- physical <= 2 : 25\n","  - toxic <= 2 : 6\n","  - toxic >= 3 : 19\n","- il <= 2 : 25\n","  - toxic <= 2 : 6\n","  - toxic >= 3 : 19\n","- pm <= 2 : 45\n","  - toxic <= 2 : 23\n","  - toxic >= 3 : 22\n","- other <= 2 : 5 "],"metadata":{"id":"3W2AunS_D2y8"}},{"cell_type":"code","source":["### physical_cat : 25\n","train_p1 = train[((train['physical_cat'] == '1') | (train['physical_cat'] == '2')) & ((train['toxic_class'] == '1VeryToxic') | (train['toxic_class'] == '2Toxic'))] # 6개 : get all\n","train_p2 = train[((train['physical_cat'] == '1') | (train['physical_cat'] == '2')) & ((train['toxic_class'] == '3HardtoSay') | (train['toxic_class'] == '4NotToxic'))].head(19) # 19개\n","\n","### il_cat : 25\n","train_i1 = train[((train['il_cat'] == '1') | (train['il_cat'] == '2')) & ((train['toxic_class'] == '1VeryToxic') | (train['toxic_class'] == '2Toxic'))] # 6개 : get all\n","train_i2 = train[((train['il_cat'] == '1') | (train['il_cat'] == '2')) & ((train['toxic_class'] == '3HardtoSay') | (train['toxic_class'] == '4NotToxic'))].head(19) # 19개\n","\n","### pm_cat : 45\n","train_pm1 = train[((train['pm_cat'] == '1') | (train['pm_cat'] == '2')) & ((train['toxic_class'] == '1VeryToxic') | (train['toxic_class'] == '2Toxic'))].head(23)\n","train_pm2 = train[((train['pm_cat'] == '1') | (train['pm_cat'] == '2')) & ((train['toxic_class'] == '3HardtoSay') | (train['toxic_class'] == '4NotToxic'))].head(22)\n","\n","### other : 5\n","train_o = train[train['other_cat'] == '2'] # 5개"],"metadata":{"id":"UJYh8klcDyVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.concat([train_p1, train_p2, train_i1, train_i2, train_pm1, train_pm2, train_o])"],"metadata":{"id":"vmWrWxkEED-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.toxic_class.value_counts().sort_index()"],"metadata":{"id":"WfORAsEODA24"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Separate & Save\n","- df1 50 : df2 50"],"metadata":{"id":"muGSubw1G48V"}},{"cell_type":"code","source":["df1 = df.head(50)\n","df2 = df.tail(50)"],"metadata":{"id":"uaadU2FqFi5p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.to_pickle(path+\"dataset/train_find_disability_words_1.pkl\")\n","df2.to_pickle(path+\"dataset/train_find_disability_words_2.pkl\")"],"metadata":{"id":"7RpmmaQgDA9_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Find words related to disabilities manually\n","\n","### 5.1 df1"],"metadata":{"id":"Rh8dlat_Hr1L"}},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', None)\n","df1 = pd.read_pickle(path+\"dataset/train_find_disability_words_1.pkl\")"],"metadata":{"id":"ry8pEe8MWh3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# method suggestion : not change but omit?? -> bc words look hard to change\n","# mentally/physically disabiled/ill\n","# psychological illnesses\n","# disabled man\n","# autistic kids\n","dis_words1 = ['disability', 'drug addiction', 'quadriplegic', 'blind', 'disabled', 'handicap', 'health problems', # first 5\n","             'ill', 'PTSD', 'mentally vulnerable', 'physically impaired', 'illness', 'coma', 'ODSP', 'weakest', 'disabilities', 'illnesses', 'Schizophrenia', # next 5\n","             'mental health issues', 'addiction to drugs', 'amputees', 'wheelchair', 'medicine',\n","             'Disease', 'MS', 'physical or mental issues', 'physical or mental disabilities', 'physically disabled', 'lunatics', 'physical and mental disabilities', 'contagious disease',\n","             'retard', 'autism', 'loony', 'Intellectual disability', 'fathisht',\n","             'intellectual disabled', 'mental illness', 'intelectual disabilities', 'autistic', 'retardation', 'genetic defects',\n","             'learning disabilities', 'birth defects', 'stomach problems',\n","             'learning disabilities', 'inferior', 'brain disorder', 'disorder', 'auts and asps', 'developmental disorders',\n","             'dementia', 'ASD']"],"metadata":{"id":"D2zHocVBznSC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.2 df2"],"metadata":{"id":"inILCETdH6dG"}},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', None)\n","df2 = pd.read_pickle(path+\"dataset/train_find_disability_words_2.pkl\")"],"metadata":{"id":"t8tkgS04H6fc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dis_words2 = ['mental disorders', 'mental health', 'psychosis', 'addiction', 'drug addicted','mental illness', 'dementia',\n","              'mentally ill', 'narcissistic personality disorder', 'blinds','mental health disorder', 'malignant narcissist',\n","              'sociopath', 'mental disorder', 'delusions', 'mentally handicapped', 'psychotic', 'mental state', 'severe mental disorder',\n","              'severe mental health', 'mental health issues', 'psychiatric', 'mental health crisis', 'mentally unstable',\n","              'untreated mental health issues', 'handicapped', 'psychotropic', 'learning disabilities', 'brain dysfunction',\n","              'hysteria', 'physiological mental health', 'disabled', 'disabilities']"],"metadata":{"id":"3uAi3YYEDSb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Omit words related to disabilites\n","- words found from 100 sentences randomly selected"],"metadata":{"id":"oayxpBJSDBjS"}},{"cell_type":"code","source":["train = pd.read_pickle(path+\"dataset/train.pkl\")"],"metadata":{"id":"iQGbNAL8Ddfr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def omit_dis(df):\n","\n","    rst = []\n","    for word in df:\n","        if word not in dis_words1 and word not in dis_words2:\n","            rst.append(word)\n","\n","    return rst"],"metadata":{"id":"a2oztZd5DBln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train['disabled_omit'] = train['tokenized'].apply(lambda x: omit_dis(x))"],"metadata":{"id":"lQlxLGfJDBnv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Save"],"metadata":{"id":"2SUQSync6oNi"}},{"cell_type":"code","source":["l = len(train)\n","\n","train1 = train[:int(l*(1/3))]\n","train2 = train[int(l*(1/3)):int(l*(2/3))]\n","train3 = train[int(l*(2/3)):]"],"metadata":{"id":"cS_I7UcSDBpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train1.to_pickle(path+\"dataset/train_disability_omit1.pkl\")\n","train2.to_pickle(path+\"dataset/train_disability_omit2.pkl\")\n","train3.to_pickle(path+\"dataset/train_disability_omit3.pkl\")"],"metadata":{"id":"gOBXiL7cDZ9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train1) + len(train2) + len(train3))\n","print(len(train))"],"metadata":{"id":"BduUAMZK4Yss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train1 = pd.read_pickle(path+\"dataset/train_disability_omit1.pkl\")\n","train2 = pd.read_pickle(path+\"dataset/train_disability_omit2.pkl\")\n","train3 = pd.read_pickle(path+\"dataset/train_disability_omit3.pkl\")"],"metadata":{"id":"M0jANR9h7WaW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.concat([train1, train2, train3])"],"metadata":{"id":"YHEQwngEcC5Q"},"execution_count":null,"outputs":[]}]}